{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nnltk.download('stopwords')\nnltk.download('wordnet')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n!pip install contractions\nimport contractions\nimport re\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-21T16:48:12.699320Z","iopub.execute_input":"2022-08-21T16:48:12.699742Z","iopub.status.idle":"2022-08-21T16:48:30.715366Z","shell.execute_reply.started":"2022-08-21T16:48:12.699653Z","shell.execute_reply":"2022-08-21T16:48:30.714297Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from platform import python_version\n\nprint(python_version())","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:30.716865Z","iopub.execute_input":"2022-08-21T16:48:30.717159Z","iopub.status.idle":"2022-08-21T16:48:30.722243Z","shell.execute_reply.started":"2022-08-21T16:48:30.717130Z","shell.execute_reply":"2022-08-21T16:48:30.721086Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"tf.version.VERSION","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:30.724379Z","iopub.execute_input":"2022-08-21T16:48:30.724979Z","iopub.status.idle":"2022-08-21T16:48:30.739163Z","shell.execute_reply.started":"2022-08-21T16:48:30.724935Z","shell.execute_reply":"2022-08-21T16:48:30.738083Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:30.741220Z","iopub.execute_input":"2022-08-21T16:48:30.742001Z","iopub.status.idle":"2022-08-21T16:48:30.867490Z","shell.execute_reply.started":"2022-08-21T16:48:30.741958Z","shell.execute_reply":"2022-08-21T16:48:30.866435Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/emotions/train.txt', names=['text', 'emotion'], sep=';')\nval_data = pd.read_csv('/kaggle/input/emotions/val.txt', names=['text', 'emotion'], sep=';')\ntest_data = pd.read_csv('/kaggle/input/emotions/test.txt', names=['text', 'emotion'], sep=';')\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:30.868879Z","iopub.execute_input":"2022-08-21T16:48:30.869479Z","iopub.status.idle":"2022-08-21T16:48:30.989418Z","shell.execute_reply.started":"2022-08-21T16:48:30.869434Z","shell.execute_reply":"2022-08-21T16:48:30.988348Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:30.990831Z","iopub.execute_input":"2022-08-21T16:48:30.991337Z","iopub.status.idle":"2022-08-21T16:48:31.046677Z","shell.execute_reply.started":"2022-08-21T16:48:30.991200Z","shell.execute_reply":"2022-08-21T16:48:31.045580Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test_data.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:31.047904Z","iopub.execute_input":"2022-08-21T16:48:31.048212Z","iopub.status.idle":"2022-08-21T16:48:31.063978Z","shell.execute_reply.started":"2022-08-21T16:48:31.048185Z","shell.execute_reply":"2022-08-21T16:48:31.062961Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"val_data.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:31.065494Z","iopub.execute_input":"2022-08-21T16:48:31.065803Z","iopub.status.idle":"2022-08-21T16:48:31.081578Z","shell.execute_reply.started":"2022-08-21T16:48:31.065772Z","shell.execute_reply":"2022-08-21T16:48:31.080817Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"**Check for null values in train, val and test dataset**","metadata":{}},{"cell_type":"code","source":"data = {'Train Data': train_data, 'Validation Data': val_data, 'Test Data': test_data}\nfor temp in data:\n    print(temp)\n    print(data[temp].isnull().sum())\n    print('*'*20)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:31.084060Z","iopub.execute_input":"2022-08-21T16:48:31.084577Z","iopub.status.idle":"2022-08-21T16:48:31.099318Z","shell.execute_reply.started":"2022-08-21T16:48:31.084543Z","shell.execute_reply":"2022-08-21T16:48:31.098320Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Class Distribution in Train, val and test dataset**","metadata":{}},{"cell_type":"code","source":"bar, ax = plt.subplots(1,3, figsize=(30, 10))\nfor index, temp in enumerate(data):\n    sns.countplot(ax = ax[index],x = 'emotion', data = data[temp])\n    ax[index].set_title(temp+' Class Frequency', size=14)\n    ax[index].set_ylabel('Frequency', size=14)\n    ax[index].set_xlabel(temp+' Class', size=14)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:31.101338Z","iopub.execute_input":"2022-08-21T16:48:31.102022Z","iopub.status.idle":"2022-08-21T16:48:31.591472Z","shell.execute_reply.started":"2022-08-21T16:48:31.101985Z","shell.execute_reply":"2022-08-21T16:48:31.590666Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"It is evident that dataset is highly imbalanced. \"Joy\" class has highest frequency  and 'Surprise' have least frequency in all three datasets.","metadata":{}},{"cell_type":"markdown","source":"**Word Cloud** to get most frequent words.","metadata":{}},{"cell_type":"code","source":"def plot_cloud(wordcloud, temp):\n    plt.figure(figsize=(10, 10))\n    plt.title(temp+' Word Cloud', size = 16)\n    plt.imshow(wordcloud) \n    # No axis details\n    plt.axis(\"off\");","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:31.592726Z","iopub.execute_input":"2022-08-21T16:48:31.593330Z","iopub.status.idle":"2022-08-21T16:48:31.598745Z","shell.execute_reply.started":"2022-08-21T16:48:31.593284Z","shell.execute_reply":"2022-08-21T16:48:31.597901Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for temp in data:\n    temp_text = ' '.join([sentence for sentence in data[temp].text])\n    wordcloud = WordCloud(width = 600, height = 600).generate(temp_text)\n    plot_cloud(wordcloud, temp)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:31.599974Z","iopub.execute_input":"2022-08-21T16:48:31.600414Z","iopub.status.idle":"2022-08-21T16:48:36.210618Z","shell.execute_reply.started":"2022-08-21T16:48:31.600384Z","shell.execute_reply":"2022-08-21T16:48:36.209653Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Pre-Processing","metadata":{}},{"cell_type":"markdown","source":"**Preprocessing includes:**\n1. Removing stopwords (without removing negative words)\n2. Expand Contractions\n3. Lemmatization\n\n**Note:** Negative words are removed from the set of stopwords as it makes \"I am not happy\" to \"happy\" after preprocessing. In short, it can change the semantic meaning of sentence and result into wrong training.","metadata":{}},{"cell_type":"code","source":"def preprocess(sentence):\n    stop_words = set(stopwords.words('english'))\n    lemmatizer = WordNetLemmatizer()\n    sentence = re.sub('[^A-z]', ' ', sentence)\n    negative = ['not', 'neither', 'nor', 'but', 'however',\n                'although', 'nonetheless', 'despite', 'except',\n                        'even though', 'yet']\n    stop_words = [z for z in stop_words if z not in negative]\n    preprocessed_tokens = [lemmatizer.lemmatize(contractions.fix(temp.lower())) for temp in sentence.split() if temp not in stop_words] #lemmatization\n    return ' '.join([x for x in preprocessed_tokens]).strip()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:36.211818Z","iopub.execute_input":"2022-08-21T16:48:36.212155Z","iopub.status.idle":"2022-08-21T16:48:36.218355Z","shell.execute_reply.started":"2022-08-21T16:48:36.212123Z","shell.execute_reply":"2022-08-21T16:48:36.217419Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data['text'] = train_data['text'].apply(lambda x: preprocess(x))\nval_data['text'] = val_data['text'].apply(lambda x: preprocess(x))\ntest_data['text'] = test_data['text'].apply(lambda x: preprocess(x))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:36.219388Z","iopub.execute_input":"2022-08-21T16:48:36.219730Z","iopub.status.idle":"2022-08-21T16:48:46.088574Z","shell.execute_reply.started":"2022-08-21T16:48:36.219700Z","shell.execute_reply":"2022-08-21T16:48:46.087288Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**Note:** As class imbalanced is evident, RandomOverSampler is used to add data(repetition) to all classes except highest frequency class.","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=0)\ntrain_x, train_y = ros.fit_resample(np.array(train_data['text']).reshape(-1, 1), np.array(train_data['emotion']).reshape(-1, 1))\ntrain = pd.DataFrame(list(zip([x[0] for x in train_x], train_y)), columns = ['text', 'emotion'])","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:46.089966Z","iopub.execute_input":"2022-08-21T16:48:46.090281Z","iopub.status.idle":"2022-08-21T16:48:46.424032Z","shell.execute_reply.started":"2022-08-21T16:48:46.090249Z","shell.execute_reply":"2022-08-21T16:48:46.422939Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Applying OneHotEncoder on target of all dataset","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.OneHotEncoder()\ny_train= le.fit_transform(np.array(train['emotion']).reshape(-1, 1)).toarray()\ny_test= le.fit_transform(np.array(test_data['emotion']).reshape(-1, 1)).toarray()\ny_val= le.fit_transform(np.array(val_data['emotion']).reshape(-1, 1)).toarray()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:46.425310Z","iopub.execute_input":"2022-08-21T16:48:46.425611Z","iopub.status.idle":"2022-08-21T16:48:46.441609Z","shell.execute_reply.started":"2022-08-21T16:48:46.425581Z","shell.execute_reply":"2022-08-21T16:48:46.440220Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Encoding","metadata":{}},{"cell_type":"markdown","source":"There is a very helpful function called encode_plus provided in the Tokenizer class. It can seamlessly perform the following operations:\n\n* Tokenize the text and Add special tokens - [CLS] and [SEP]\n* create input IDs\n* Pad the sentences to a maximum length\n* Create attention masks for the above PAD tokens\n\n**Note:** RoBERTa uses byte-level Byte-Pair Encoding (BPE) in contrast to BERT’s character-level BPE.","metadata":{}},{"cell_type":"code","source":"from transformers import RobertaTokenizerFast\ntokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:46.442750Z","iopub.execute_input":"2022-08-21T16:48:46.443225Z","iopub.status.idle":"2022-08-21T16:48:51.087473Z","shell.execute_reply.started":"2022-08-21T16:48:46.443190Z","shell.execute_reply":"2022-08-21T16:48:51.086280Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def roberta_encode(data,maximum_length) :\n  input_ids = []\n  attention_masks = []\n  \n\n  for i in range(len(data.text)):\n      encoded = tokenizer.encode_plus(\n        \n        data.text[i],\n        add_special_tokens=True,\n        max_length=maximum_length,\n        pad_to_max_length=True,\n        \n        return_attention_mask=True,\n        \n      )\n      \n      input_ids.append(encoded['input_ids'])\n      attention_masks.append(encoded['attention_mask'])\n  return np.array(input_ids),np.array(attention_masks)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:51.089207Z","iopub.execute_input":"2022-08-21T16:48:51.089535Z","iopub.status.idle":"2022-08-21T16:48:51.097448Z","shell.execute_reply.started":"2022-08-21T16:48:51.089503Z","shell.execute_reply":"2022-08-21T16:48:51.095983Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"max_len = max([len(x.split()) for x in train_data['text']])\ntrain_input_ids,train_attention_masks = roberta_encode(train, max_len)\ntest_input_ids,test_attention_masks = roberta_encode(test_data, max_len)\nval_input_ids,val_attention_masks = roberta_encode(val_data, max_len)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:48:51.098985Z","iopub.execute_input":"2022-08-21T16:48:51.099328Z","iopub.status.idle":"2022-08-21T16:48:54.929840Z","shell.execute_reply.started":"2022-08-21T16:48:51.099293Z","shell.execute_reply":"2022-08-21T16:48:54.928656Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"markdown","source":"**How RoBERTa is better than BERT ??**\n\nChanges in Pre-Training:\n* without NSP objective \n* with dynamic mask generation\n\nChanges in Data:\n* Trained on more data (16GB BERT vs 160GB RoBERTa)\n* Trained on large batches\n\n**Note:** Pre-requistics is to go through BERT\n\nReferences:\n* Bert: https://arxiv.org/pdf/1810.04805.pdf\n* The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning): http://jalammar.github.io/illustrated-bert/\n* The Illustrated Transformer: https://jalammar.github.io/illustrated-transformer/\n* Attention Is All You Need: https://arxiv.org/pdf/1706.03762.pdf\n* Query,key,value vector: https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms","metadata":{}},{"cell_type":"code","source":"def create_model(bert_model, max_len):\n    input_ids = tf.keras.Input(shape=(max_len,),dtype='int32')\n    attention_masks = tf.keras.Input(shape=(max_len,),dtype='int32')\n\n    output = bert_model([input_ids,attention_masks])\n    output = output[1]\n    \n    output = tf.keras.layers.Dense(4, activation='softmax')(output)\n    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n    model.compile(Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:50:55.106377Z","iopub.execute_input":"2022-08-21T16:50:55.106903Z","iopub.status.idle":"2022-08-21T16:50:55.118324Z","shell.execute_reply.started":"2022-08-21T16:50:55.106859Z","shell.execute_reply":"2022-08-21T16:50:55.116877Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from transformers import TFRobertaModel\nroberta_model = TFRobertaModel.from_pretrained('roberta-base')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:50:57.549886Z","iopub.execute_input":"2022-08-21T16:50:57.550260Z","iopub.status.idle":"2022-08-21T16:51:01.740351Z","shell.execute_reply.started":"2022-08-21T16:50:57.550228Z","shell.execute_reply":"2022-08-21T16:51:01.739266Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = create_model(roberta_model, max_len)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:51:04.648369Z","iopub.execute_input":"2022-08-21T16:51:04.648748Z","iopub.status.idle":"2022-08-21T16:51:06.438484Z","shell.execute_reply.started":"2022-08-21T16:51:04.648713Z","shell.execute_reply":"2022-08-21T16:51:06.437485Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"history = model.fit([train_input_ids,train_attention_masks],\n                    y_train, validation_data=([val_input_ids,val_attention_masks], y_val),\n                    epochs=2,\n                    batch_size=100)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:51:11.289815Z","iopub.execute_input":"2022-08-21T16:51:11.290311Z","iopub.status.idle":"2022-08-21T18:49:30.745483Z","shell.execute_reply.started":"2022-08-21T16:51:11.290272Z","shell.execute_reply":"2022-08-21T18:49:30.744247Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"**Plotting Accuracy and Loss (Training and Validation)**","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:49:37.817257Z","iopub.status.idle":"2022-08-21T16:49:37.817763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:49:37.818716Z","iopub.status.idle":"2022-08-21T16:49:37.819171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RoBERTa Model prediction on Test Data**","metadata":{}},{"cell_type":"code","source":"result = model.predict([test_input_ids,test_attention_masks])\ny_pred = np.zeros_like(result)\ny_pred[np.arange(len(result)), result.argmax(1)] = 1","metadata":{"execution":{"iopub.status.busy":"2022-08-21T18:51:49.390795Z","iopub.execute_input":"2022-08-21T18:51:49.391285Z","iopub.status.idle":"2022-08-21T18:54:04.617725Z","shell.execute_reply.started":"2022-08-21T18:51:49.391237Z","shell.execute_reply":"2022-08-21T18:54:04.616829Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"**Accuracy and F1 Score of Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy ', accuracy)\nf1 = f1_score(y_test, y_pred, average = 'macro')\nprint('F1 Score :', f1)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T18:54:04.620277Z","iopub.execute_input":"2022-08-21T18:54:04.620722Z","iopub.status.idle":"2022-08-21T18:54:04.641585Z","shell.execute_reply.started":"2022-08-21T18:54:04.620676Z","shell.execute_reply":"2022-08-21T18:54:04.640858Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, multilabel_confusion_matrix\n\nprint(classification_report(y_test, y_pred, target_names=[ \"sadness\", \"joy\", \"anger\", \"fear\"], digits=4))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T18:56:33.460713Z","iopub.execute_input":"2022-08-21T18:56:33.461514Z","iopub.status.idle":"2022-08-21T18:56:33.483941Z","shell.execute_reply.started":"2022-08-21T18:56:33.461470Z","shell.execute_reply":"2022-08-21T18:56:33.482731Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Save the weights\nmodel.save_weights('my_checkpoint.h5')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T18:56:43.868649Z","iopub.execute_input":"2022-08-21T18:56:43.869206Z","iopub.status.idle":"2022-08-21T18:56:45.678592Z","shell.execute_reply.started":"2022-08-21T18:56:43.869153Z","shell.execute_reply":"2022-08-21T18:56:45.677484Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'./')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:49:37.824500Z","iopub.status.idle":"2022-08-21T16:49:37.824933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'./my_checkpoint.h5')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:49:37.825650Z","iopub.status.idle":"2022-08-21T16:49:37.826061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Inference","metadata":{}},{"cell_type":"code","source":"def plot_result(result):\n    sns.barplot(x = 'Category', y = 'Confidence', data = result)\n    plt.xlabel('Categories', size=14)\n    plt.ylabel('Confidence', size=14)\n    plt.title('Emotion Classification', size=16)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:49:37.826785Z","iopub.status.idle":"2022-08-21T16:49:37.827245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def roberta_inference_encode(data,maximum_length) :\n    input_ids = []\n    attention_masks = []\n  \n\n  \n    encoded = tokenizer.encode_plus(\n    data,\n    add_special_tokens=True,\n    max_length=maximum_length,\n    pad_to_max_length=True,\n\n    return_attention_mask=True\n\n    )\n\n    input_ids.append(encoded['input_ids'])\n    attention_masks.append(encoded['attention_mask'])\n    return np.array(input_ids),np.array(attention_masks)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:49:37.828015Z","iopub.status.idle":"2022-08-21T16:49:37.828398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference(text_sentence, max_len):\n    preprocessed_text = preprocess(text_sentence)\n    input_ids, attention_masks = roberta_inference_encode(preprocessed_text, maximum_length = max_len)\n    model = create_model(roberta_model, 35)\n    model.load_weights('my_checkpoint.h5')\n    result = model.predict([input_ids, attention_masks])\n#     le.categories_[0] = ['anger' 'fear' 'joy' 'love' 'sadness' 'surprise']\n    result = pd.DataFrame(dict(zip(list(le.categories_[0]), [round(x*100, 2)for x in result[0]])).items(), columns = ['Category', 'Confidence'])\n    plot_result(result)\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:49:37.829186Z","iopub.status.idle":"2022-08-21T16:49:37.829605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inference","metadata":{"execution":{"iopub.status.busy":"2022-08-21T16:49:37.830805Z","iopub.status.idle":"2022-08-21T16:49:37.831297Z"},"trusted":true},"execution_count":null,"outputs":[]}]}